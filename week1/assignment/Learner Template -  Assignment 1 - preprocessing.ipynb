{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Dk1_z5YZqToN"
      },
      "source": [
        "# Text Acquisition and Pre-processing\n",
        "\n",
        "In this assignment you will practice obtaining, extracting, cleaning and pre-processing text from an online source. The objective is to obtain the text from a web page and generate a **pandas** DataFrame containing the text segmented, tokenized and with different types of linguistic annotations.\n",
        "\n",
        "You will work with the following objects and functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DQeaQRN_qToP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6-aaLtZNqToR"
      },
      "source": [
        "## Text Extraction   - [3 Marks]\n",
        "\n",
        "The text you are going to work with corresponds to the following post from the Food and Agriculture Organization of the United Nations website: [World food prices dip in December](https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en).\n",
        "\n",
        "In a more realistic scenario, you should download the html document yourself. This could be done with the following code snippet:\n",
        "\n",
        ">```python\n",
        "import requests\n",
        "URL = \"https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en\"\n",
        "page = requests.get(URL)\n",
        "html_content = page.content\n",
        "\n",
        "However, for this assignment, you are provided with the downloaded document. The file`world-food-prices.html` can be found in the same directory as this notebook and it can be opened as a regular text file:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/thanhxuan1995/NLP/raw/2e7756ba9f61aa7c1c4dee26d391540462cb7b24/week1/assignment/world-food-prices.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLY_FdbSGu-j",
        "outputId": "0940d3bd-b151-49fd-e9bf-e83f39909a62"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-19 02:46:59--  https://github.com/thanhxuan1995/NLP/raw/2e7756ba9f61aa7c1c4dee26d391540462cb7b24/week1/assignment/world-food-prices.html\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/thanhxuan1995/NLP/2e7756ba9f61aa7c1c4dee26d391540462cb7b24/week1/assignment/world-food-prices.html [following]\n",
            "--2025-01-19 02:47:00--  https://raw.githubusercontent.com/thanhxuan1995/NLP/2e7756ba9f61aa7c1c4dee26d391540462cb7b24/week1/assignment/world-food-prices.html\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42568 (42K) [text/plain]\n",
            "Saving to: ‘world-food-prices.html.2’\n",
            "\n",
            "world-food-prices.h 100%[===================>]  41.57K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-01-19 02:47:00 (3.63 MB/s) - ‘world-food-prices.html.2’ saved [42568/42568]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Wnpli1_pqToR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "eb2f0d8e-c665-443f-f101-15502a05c24e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> <title>\\n\\tWorld food prices dip in December\\n</title> <script src=\"/ScriptResource.axd?d=okuX3IVIBwfJlfEQK32K3hu4wA2qYZOscmtsXGLNMaT1SeSa2ByRKpPz9pkmicdQmLZjrfXbzQg-t-PYtREZ1mv-AHy-XqG8V1C8KEuJc1LwVjfZ2AWtsXusqOzwjxwAkWajaiTob5rdLJ_1Q_rhyISygdJ2WS4kb3-Mf0bSt_7dAdqZ2JnDovQKGlnv0vvH0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"/ScriptResource.axd?d=ePnjFy9PuY6CB3GWMX-b_9Fw4jG3rW51lh6cTRiQ1f_9YOhRVOpDf4gVRQwVzn4JRlDVp-Aj_GWhYCgMY8uVHBZj_w4a27EVOxonvJSMs3yERFILsgdOHu7up3GVU-jExdmK0YWhyY1E0W4ye5rzFrSYUigZQBN7nFt18-5XwfQs2ZTBZ5-Na5q3Phaw58Dx0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"https://cse.google.com/cse.js?cx=018170620143701104933%3Aqq82jsfba7w\" type=\"text/javascript\"></script><link href=\"/ResourcePackages/FAO/assets/dist/css/bootstrap.min.css?v=5.2.0&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <link href=\"/ResourcePackages/FAO/assets/dist/css/fao-theme.min.css?v=2.6.6&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <!-- Google Tag Manager -->\\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\\'gtm.start\\':\\nnew Date().getTime(),event:\\'gtm.js\\'});var f=d.getElementsByTagName(s)[0],\\nj=d.createElement(s),dl=l!=\\'dataLayer\\'?\\'&l=\\'+l:\\'\\';j.async=true;j.src=\\n\\'https://www.googletagmanager.com/gtm.js?id=\\'+i+dl;f.parentNode.insertBefore(j,f);\\n})(window,document,\\'script\\',\\'d'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "with open(\"world-food-prices.html\", encoding=\"utf8\") as html_file:\n",
        "    html_content = html_file.read()\n",
        "html_content[:1500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "zJla0Pz7qToR"
      },
      "source": [
        " As you can see the document contains a lot of html tags as well as some **javascript** code. The text also includes fields that are not of interest, such as the navigation menu of the web page. The goal of the first step in this assignment is to extract only the text from the body of the post.   \n",
        "\n",
        "To do this, you must complete the code for the `extract_text` function. This function should parse the content of the html document using the **BeatifulSoup** library, find the html element containing the text of the body of the post, and extract such text. The body of the post is contained by the element with the following **id**: `\"Contentplaceholder1_C011_Col00\"`. Review the [BeautifullSoup documentation](https://beautiful-soup-4.readthedocs.io/en/latest/index.html) to learn how to perform these steps.\n",
        "\n",
        "\n",
        "The function must return the text extracted of which the first 579 characters should look like this:\n",
        "\n",
        "\n",
        "><pre>'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "vNP3kX3EqToS"
      },
      "outputs": [],
      "source": [
        "def extract_text(html_content):\n",
        "    # using beatiful soup to extract body of text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    # find content element\n",
        "    content_element = soup.find(id = 'Contentplaceholder1_C011_Col00')\n",
        "    # Extract the text from the element\n",
        "    if content_element:\n",
        "        text = content_element.get_text()\n",
        "        return text\n",
        "    else:\n",
        "        return None\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "H7wioy8qqToS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4e7f1c0a-131c-4b8e-a92a-1d7dfb3e6199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "text = extract_text(html_content)\n",
        "text[:580]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "tSUhC6SEqToS"
      },
      "source": [
        "## Text Cleanup  - [3 Marks]\n",
        "\n",
        " The text extracted by `extract_text` is not still ready to use. It contains several newline characters and additional spaces that make the text noisy. In the next step of the assignment, you must complete the code for the function `clean_text`. The function should take the text and delete all those newline characters and extra blank spaces. The function should also add a period to the end of those sentences that do not originally contain it, for example, `World food prices dip in December` or `06/01/2023`.\n",
        "\n",
        "You can solve this exercise using the **Python** built-in [string methods](https://docs.python.org/3.9/library/stdtypes.html?highlight=replace#str), such as `replace`, or by [regular expressions](https://docs.python.org/3.9/library/re.html?highlight=re#module-re).\n",
        "\n",
        "The `extract_text` function must return the cleaned text of which the first 499 characters should look like this:\n",
        "\n",
        ">'World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "K4sDyMtNqToT"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove newline characters and extra spaces\n",
        "    text = re.sub(r'\\n+', '.', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    sentences = text.split('.')\n",
        "    # Remove empty or None values from the list of sentences\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "    # now, add in period into the sentenc whic dont have it.\n",
        "    modified_sentences = []\n",
        "    for sentence in sentences[1:]:\n",
        "        if not sentence.endswith('.'):\n",
        "            modified_sentences.append(sentence + '.')\n",
        "        else:\n",
        "            modified_sentences.append(sentence)\n",
        "    text = ' '.join(modified_sentences)\n",
        "    return text\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tc-I4qJYqToT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2a088825-f973-44d6-8176-5ac3b72cc83b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1. 9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132. 4 points in December, 1. 0 percent below its value a year earlier. However, for 2022 as a whole, t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "cleaned_text = clean_text(text)\n",
        "cleaned_text[:499]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "eA3IF-6CqToT"
      },
      "source": [
        "## Pre-processing  - [3 Marks]\n",
        "\n",
        "Once the text has been extracted and cleaned up, the next step you must take is to pre-process it. For this, in this assignment, you are going to use the [spaCy](https://spacy.io/) library. This library is an advanced NLP toolkit that allows to execute various pre-processing steps as well as different NLP tasks. **spaCy** provides trained [pipelines](https://spacy.io/usage/processing-pipelines) for a variety of languages that can be installed as individual **Python** modules and include [linguistic featues](https://spacy.io/usage/linguistic-features) such as:\n",
        "\n",
        "- Sentence Segmentation\n",
        "- Tokenization\n",
        "- Stemming and Lemmatization\n",
        "- Stopwords\n",
        "- Part-of-speech tagging\n",
        "- Syntactic dependency parsing\n",
        "- Named Entity Recognition\n",
        "- Word Embeddings\n",
        "\n",
        "In this exercise, you will work with the [English pipeline optimized for CPU](https://spacy.io/models/en#en_core_web_sm) that can be loaded as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "KLveisvrqToU"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "20ZEJxrwqToU"
      },
      "source": [
        " You must complete the code for the `preprocess_text` function. This function takes the text and a **spaCy** pipeline as input and should run that pipeline on the text. The function must return a [Doc](https://spacy.io/api/doc) object. Check the [spaCy 101](https://spacy.io/usage/spacy-101) documentation to learn how to apply the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExmJQppvqToU"
      },
      "outputs": [],
      "source": [
        "def process_text(text, nlp):\n",
        "    #\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pfyti4fRqToU"
      },
      "outputs": [],
      "source": [
        "doc = process_text(cleaned_text, nlp)\n",
        "all(map(doc.has_annotation, [\"LEMMA\", \"POS\", \"ENT_TYPE\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "U4jEaviHqToU"
      },
      "source": [
        "## Creating a DataFrame  - [3 Marks]\n",
        "\n",
        "In the next exercise, you will create a [pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that will contain some of the linguistic annotations from the `Doc` object obtained in the previous step. Loading the data into a `DataFrame` provides some advantages such as a better integration with other **Python** machine learning libraries or the option to save the data in a csv file.\n",
        "\n",
        "The goal is to create a `DataFrame` that contains a row per each token in the `Doc` and the following columns:\n",
        "- *sent_id*: The id of the sentence the token belongs to. It represents the position of the sentence in the `Doc`, starting by 0.\n",
        "- *token_id*: The id of the token. It represents the position of the token in the sentence, starting by 0.\n",
        "- *text*: The original text of the token.\n",
        "- *lemma*: The lemmatization of the token.\n",
        "- *pos*: The part-of-speech of the token.\n",
        "- *ent*: The entity type of the token returned by the Named Entity Recognition component.\n",
        "\n",
        "You must complete the code for the `to_dataframe` function. This function takes the [Doc](https://spacy.io/api/doc) object and must return the `DataFrame` described above. The function should iterate over the sentences in the `Doc` (each sentence is a [Span](https://spacy.io/api/span) object) and, for each sentence, it should iterate over its tokens (each token is a [Token](https://spacy.io/api/token) object). For each token, `to_dataframe` should obtain the values to fill the *text*, *lemma*, *pos* and *ent* columns of the `DataFrame`. For example, the content of the `DataFrame` for the setence with *sent_id* equal to 1, corresponding to the second sentence in the `Doc`, should look like this:\n",
        "\n",
        "|    |   sent_id |   token_id | text    | lemma   | pos   | ent   |\n",
        "|---:|----------:|-----------:|:--------|:--------|:------|:------|\n",
        "|  7 |         1 |          0 | FAO     | FAO     | PROPN | ORG   |\n",
        "|  8 |         1 |          1 | Food    | Food    | PROPN | ORG   |\n",
        "|  9 |         1 |          2 | Price   | Price   | PROPN | ORG   |\n",
        "| 10 |         1 |          3 | Index   | Index   | PROPN | ORG   |\n",
        "| 11 |         1 |          4 | ends    | end     | VERB  |       |\n",
        "| 12 |         1 |          5 | 2022    | 2022    | NUM   | DATE  |\n",
        "| 13 |         1 |          6 | lower   | low     | ADJ   |       |\n",
        "| 14 |         1 |          7 | than    | than    | ADP   |       |\n",
        "| 15 |         1 |          8 | a       | a       | DET   | DATE  |\n",
        "| 16 |         1 |          9 | year    | year    | NOUN  | DATE  |\n",
        "| 17 |         1 |         10 | earlier | early   | ADV   | DATE  |\n",
        "| 18 |         1 |         11 | .       | .       | PUNCT |       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVnsUqrLqToU"
      },
      "outputs": [],
      "source": [
        "def to_dataframe(doc):\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9fHv9X5oqToU"
      },
      "outputs": [],
      "source": [
        "df = to_dataframe(doc)\n",
        "df[df.sent_id == 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "96JJ-WtXqToU"
      },
      "source": [
        "## Cutomizing the Tokenizer  - [3 Marks]\n",
        "\n",
        "The default components of a **spaCy** pipeline will not always behave according to the needs of your projects. For example, the default tokenizer of the `en_core_web_sm` pipeline does not always splits dates in `month/day/year` format into `month`, `day` and `year`. This is the case for the sentence with *sent_id* equal to 4 that only includes a date in that format:\n",
        "\n",
        "|    |   sent_id |   token_id | text       | lemma      | pos   | ent   |\n",
        "|---:|----------:|-----------:|:-----------|:-----------|:------|:------|\n",
        "| 32 |         4 |          0 | 06/01/2023 | 06/01/2023 | NUM   |       |\n",
        "| 33 |         4 |          1 | .          | .          | PUNCT |       |\n",
        "\n",
        "The goal of the last exercise of this task is to update the `en_core_web_sm` pipeline with a custom tokenizer that forces the splitting of dates in `month/day/year` format so that the sentence above looks like this:\n",
        "\n",
        "|    |   sent_id |   token_id | text   | lemma   | pos   | ent      |\n",
        "|---:|----------:|-----------:|:-------|:--------|:------|:---------|\n",
        "| 32 |         4 |          0 | 06     | 06      | NUM   | CARDINAL |\n",
        "| 33 |         4 |          1 | /      | /       | SYM   |          |\n",
        "| 34 |         4 |          2 | 01     | 01      | NUM   |          |\n",
        "| 35 |         4 |          3 | /      | /       | SYM   |          |\n",
        "| 36 |         4 |          4 | 2023   | 2023    | NUM   |          |\n",
        "| 37 |         4 |          5 | .      | .       | PUNCT |          |\n",
        "\n",
        "You must complete the code for the `customize_tokenizer` function. The function takes the **spaCy** pipeline as input. It should updated the infixes rules of the tokenizer and return the updated version of the pipeline including the customized tokenizer. The `Tokenizer` must keep the default vocabulary and all the default prefixes, infixes and suffixes rules of the pipeline. You should only update the infixes rules adding a regular expression that captures slash (`/`) characters. The `Tokenizer` should **not** include special cases or rules for token and url matching. Check the [spacy's documentation](https://spacy.io/usage/linguistic-features#native-tokenizers) to learn how to customize the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL2xM727qToU"
      },
      "outputs": [],
      "source": [
        "def customize_tokenizer(nlp):\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "StkpF47HqToV"
      },
      "outputs": [],
      "source": [
        "customized_nlp = customize_tokenizer(nlp)\n",
        "doc = process_text(cleaned_text, customized_nlp)\n",
        "df = to_dataframe(doc)\n",
        "df[df.sent_id == 4]"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Edit Metadata",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}