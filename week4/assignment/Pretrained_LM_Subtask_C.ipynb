{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zDBF1PXEDfhw"
      },
      "source": [
        "# Pre-trained Language Models: SubTask C\n",
        "## [8 Marks]\n",
        "\n",
        "In this assignment, you will work on the [ComVE](https://competitions.codalab.org/competitions/21080) shared task that was part of SemEval-2020. The task aims to evaluate whether a system can distinguish if a natural language statement makes sense to humans or not and provide a reason. **ConVE** includes three subtasks that require models to acquire and apply commonsense knowledge. In this notebook you will focus on **SubTask C**:\n",
        "\n",
        "- Given a statement that does not make sense, generate the reason why this statement does not make sense. For each nonsensical statement, three valid reasons are given as reference:\n",
        "\n",
        "     *Statement*: He put an elephant into the fridge.  \n",
        "     *Reason A*: An elephant is much bigger than a fridge.  \n",
        "     *Reason B*: A fridge is much smaller than an elephant.  \n",
        "     *Reason C*: Most of the fridges aren't large enough to contain an elephant.\n",
        "\n",
        "     This subtask can be approached as a Sequence-to-Sequence problem where the input is the nonsensical statement and the output is a valid reason.\n",
        "\n",
        "You will fine-tune a Pre-trained Language Model with [Transformers](https://huggingface.co/docs/transformers/index) library that provides a set of tools for fine-tunning and deploying a wide variety of Pre-trained Language Models. The [Hugging Face Hub](https://huggingface.co/models) allows you to explore all the models supported by **Transformers** and even share your own models with the community. In this assignment, you will work with [BART](https://huggingface.co/docs/transformers/model_doc/bart), a pre-trained Sequence-to-Sequence model.\n",
        "\n",
        "Fine-tuning a Pre-trained Language Model usually requires a great amount of time and computational resources. Your personal computer will not be enough. In order to complete the assignment, you can work with a reduced version of the dataset and the base version of **BART**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X6DavXXpDfhy"
      },
      "outputs": [],
      "source": [
        "shrink_dataset = True\n",
        "base_model = True\n",
        "colab = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fI5Uu0_gDfhz"
      },
      "source": [
        "Although the value of these variables do not affect the tests that will evaluate your code, the output examples distributed throughout this notebook are based on a `shrink_dataset` and a `base_model` variables set as `True`, and a `colab` variable set as `False`.\n",
        "\n",
        "If you want to perform a full training of the model to obtain its real performance, you can use a cloud service like [Google Colab](https://colab.research.google.com/). **Colab** is a **Jupyter** notebook environment that supports both GPU and TPU instances, allowing training large scale Deep Learning models. Set the `shrink_dataset` and a `base_model` variables to `False`, the `colab` variable to `True`, and follow the instructions provided to you to run the notebook in **Colab**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "gEqfRl12Dfhz",
        "outputId": "4d8cf8f3-d00c-4fd5-87e5-417796021c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "if colab:\n",
        "    ! pip install transformers datasets evaluate\n",
        "    import os\n",
        "    if not os.path.exists(\"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_data_all.csv\"):\n",
        "        ! git clone https://github.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation.git SemEval2020-Task4-Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "U1c3v4XVDfhz"
      },
      "source": [
        "You will use the following objects and functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Nef4cdirDfhz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import evaluate\n",
        "from datasets import Dataset\n",
        "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "                          Seq2SeqTrainingArguments, Seq2SeqTrainer,\n",
        "                          DataCollatorForSeq2Seq, enable_full_determinism)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rjm8g6k8Dfhz"
      },
      "source": [
        "When working with Neural Networks, there are a large number of random operations such as initializing the weights of the network, shuffling the data for training, or choosing samples. This causes that different training runs of the same model can lead to different results. To ensure reproducibility, i.e. obtaining the same results in the different runs, the random number generator must be initialized with a fixed value known as seed. In Transformers, this can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9GC6UlXcDfh0"
      },
      "outputs": [],
      "source": [
        "enable_full_determinism(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "J8U_rnboDfh0"
      },
      "source": [
        "> **Note!** With models as complex as Neural Networks, reproducibility is susceptible to factors such as software versions or the hardware on which the models are run. Even with seed initialization, there may be slight differences in the results.\n",
        "\n",
        "Working with Neural Networks also involves defining a number of hyperparameters that set the configuration of the model. Finding the appropriate hyperparameter values requires training the model with different combinations and testing them on the development set. This hyperparameter tuning is a costly process that needs multiple rounds of experimentation. However, for this assignments, you will use the following values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8eBiASC4Dfh0"
      },
      "outputs": [],
      "source": [
        "epochs = 3  # Number of epochs to train the model\n",
        "train_batch_size = 8  # Number of examples used per gradient update\n",
        "learning_rate = 1e-5  # The learning rate for the optimizer\n",
        "max_length = 25  # Maximum lenght of the input sequence\n",
        "output_dir = \"modelC\"  # The output directory where the model will be written"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "eAd8K6wXDfh0"
      },
      "source": [
        "> **Note!** The notebook for this assignment provides very little guidance. You are expected to refer to the [documentation](https://huggingface.co/docs) for details on how to solve the exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kGbzR7H8Dfh0"
      },
      "source": [
        "## Loading the Pre-trained Model - [1 Mark]\n",
        "\n",
        "The first step you must perform in this assignment is to load the model and its corresponding tokenizer using the classes imported above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yk7tOsLaDfh0"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name):   #[1 Mark]\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    return model, tokenizer\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "lEVPC3rlDfh0",
        "outputId": "0cfe1650-cda5-40b1-eab5-5dbaacb185a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"facebook/bart-base\" if base_model else \"facebook/bart-large\"\n",
        "model, tokenizer = load_model(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-q7CcBksDfh1"
      },
      "source": [
        "## Data Pre-processing - [2 Marks]\n",
        "\n",
        "The **ComVE** dataset consists of 10000 nonsensical statements for the train set, 997 statements for development and 1000 for test. Each nonsensical statements comes with with three reference valid reasons. You must load the three sets into three `DataFrames`. For the training and development splits, the `DataFrame` should contain three columns: the `id` of the nonsensical statement, a `FalseSent` column with the nonsensical statement and a `reason` column with the reference reasons. For the test set, the `DataFrame` should contain five columns: the `id` of the nonsensical statement, a `FalseSent` column with the nonsensical statement and three columns (`reason1`, `reason2` and `reason3`) containing each of the reference reasons.\n",
        "\n",
        "Train DataFrame:\n",
        "\n",
        "|       |   id | FalseSent                                         | reason                                                                         |\n",
        "|------:|-----:|:--------------------------------------------------|:-------------------------------------------------------------------------------|\n",
        "|   769 |  769 | Computers is an ingredient used in preparing food | Computers are not used for food and they are not edible                        |\n",
        "| 10769 |  769 | Computers is an ingredient used in preparing food | Computer is not something that can be used in preparing food.                  |\n",
        "| 20769 |  769 | Computers is an ingredient used in preparing food | You cannot eat a computer                                                      |\n",
        "|   888 |  888 | he did hear music in his cooling glass            | cooling glass can not play the song, it's not a electronic thing to play music |\n",
        "| 10888 |  888 | he did hear music in his cooling glass            | Glass does not produce music.                                                  |\n",
        "| 20888 |  888 | he did hear music in his cooling glass            | Any sound that might be made by a cooling glass is not music.                  |\n",
        "\n",
        "Test DataFrame:\n",
        "\n",
        "|     |   id | FalseSent                                      | reason1                                                  | reason2                                                | reason3                                                            |\n",
        "|----:|-----:|:-----------------------------------------------|:---------------------------------------------------------|:-------------------------------------------------------|:-------------------------------------------------------------------|\n",
        "|  76 | 1280 | Beer that is drunk by humans is white          | Beer is made of barley and it is a yellow drink          | A beer that is drunk by humans is not white.           | Beer is brown                                                      |\n",
        "| 101 |  860 | eating trash food every day makes you stronger | eating trash food every day makes your body fat and weak | eating trash food every day is bad for your health     | Trash food could be contaminated                                   |\n",
        "| 136 |  777 | he put some cooking oil in his wine            | cooking oil will destroy the taste of the wine           | Cooking oil does not go in wine                        | Cooking oil does not taste nice and therefore would ruin the wine. |\n",
        "| 174 |  570 | Lobsters live in the mountains                 | Lobsters needs water to live                             | Lobsters live in the sea.                              | Lobsters live in the sea, not the mountains                        |\n",
        "| 210 | 1929 | the clock shows animals                        | the clock is used to show the time to people             | Clocks are required to tell the time, not show animals | a clock shows the time not animals                                 |\n",
        "| 235 | 1619 | she put the giraffe in the freezer             | A giraffe is much bigger than the freezer                | There is no way a giraffe is fitting in the freezer.   | A giraffe is too big to be put in a freezer.                       |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GVeX5et-Dfh1"
      },
      "outputs": [],
      "source": [
        "def load_data(data_csv, answers_csv, is_test=False):   # 1 Mark\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    data = pd.read_csv(data_csv)\n",
        "    answer = pd.read_csv(answers_csv, sep=',', names=['id', 'reason1', 'reason2', 'reason3'])\n",
        "    #print(data.columns)\n",
        "    #print(answer.columns)\n",
        "    df = pd.merge(data, answer, on = 'id')\n",
        "    if  is_test:\n",
        "      df = df\n",
        "    else:\n",
        "      df = pd.melt(df, id_vars=['id', 'FalseSent'], value_vars=['reason1', 'reason2', 'reason3'],value_name='reason' )\n",
        "      df.drop('variable', axis=1, inplace=True)\n",
        "    return df.reset_index(drop= True)\n",
        "    #\n",
        "    pass\n",
        "#train_data_csv = \"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_data_all.csv\"\n",
        "#train_answers_csv = \"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_answers_all.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_csv, answers_csv, is_test=False):\n",
        "    # Load the nonsensical statements (data) and the corresponding reasons (answers)\n",
        "    data = pd.read_csv(data_csv)\n",
        "    answers = pd.read_csv(answers_csv, sep=',', names=['id', 'reason1', 'reason2', 'reason3'])\n",
        "\n",
        "    # Merge the data and answers based on the 'id' column\n",
        "\n",
        "    # Initialize an empty DataFrame to hold the final data\n",
        "    if is_test:\n",
        "        # For test set, there will be 5 columns: id, FalseSent, reason1, reason2, reason3\n",
        "        df = pd.DataFrame(columns=['id', 'FalseSent', 'reason1', 'reason2', 'reason3'])\n",
        "        # Merge data and answers for the test set\n",
        "        df['id'] = data['id']\n",
        "        df['FalseSent'] = data['FalseSent']\n",
        "        df['reason1'] = answers['reason1']\n",
        "        df['reason2'] = answers['reason2']\n",
        "        df['reason3'] = answers['reason3']\n",
        "    else:\n",
        "        # For train and development sets, there will be 3 columns: id, FalseSent, reason\n",
        "        df = pd.DataFrame(columns=['id', 'FalseSent', 'reason'])\n",
        "        # Flatten the train/development data to match the format (id, FalseSent, reason)\n",
        "        df['id'] = data['id'].repeat(3)  # Repeat the id for each of the three reasons\n",
        "        df['FalseSent'] = data['FalseSent'].repeat(3)  # Repeat the nonsensical statement\n",
        "        df['reason'] = answers[['reason1', 'reason2', 'reason3']].values.flatten()  # Flatten the reasons column\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Z_4nC52uV9B9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tE231iQzDfh1",
        "outputId": "b69a0b8c-858f-46aa-ba4a-af3baa92b2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      id                                          FalseSent  \\\n",
              "769  769  Computers is an ingredient used in preparing food   \n",
              "769  769  Computers is an ingredient used in preparing food   \n",
              "769  769  Computers is an ingredient used in preparing food   \n",
              "888  888             he did hear music in his cooling glass   \n",
              "888  888             he did hear music in his cooling glass   \n",
              "888  888             he did hear music in his cooling glass   \n",
              "\n",
              "                                                                             reason  \n",
              "769                         Computers are not used for food and they are not edible  \n",
              "769                   Computer is not something that can be used in preparing food.  \n",
              "769                                                       You cannot eat a computer  \n",
              "888  cooling glass can not play the song, it's not a electronic thing to play music  \n",
              "888                                                   Glass does not produce music.  \n",
              "888                   Any sound that might be made by a cooling glass is not music.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62d288e6-4da5-478c-a37a-2b952eeeaa46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>FalseSent</th>\n",
              "      <th>reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>769</td>\n",
              "      <td>Computers is an ingredient used in preparing food</td>\n",
              "      <td>Computers are not used for food and they are not edible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>769</td>\n",
              "      <td>Computers is an ingredient used in preparing food</td>\n",
              "      <td>Computer is not something that can be used in preparing food.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>769</td>\n",
              "      <td>Computers is an ingredient used in preparing food</td>\n",
              "      <td>You cannot eat a computer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>888</td>\n",
              "      <td>he did hear music in his cooling glass</td>\n",
              "      <td>cooling glass can not play the song, it's not a electronic thing to play music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>888</td>\n",
              "      <td>he did hear music in his cooling glass</td>\n",
              "      <td>Glass does not produce music.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>888</td>\n",
              "      <td>he did hear music in his cooling glass</td>\n",
              "      <td>Any sound that might be made by a cooling glass is not music.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62d288e6-4da5-478c-a37a-2b952eeeaa46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62d288e6-4da5-478c-a37a-2b952eeeaa46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62d288e6-4da5-478c-a37a-2b952eeeaa46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0f2762fc-4c3e-42fe-8b90-33347f6bfe1e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f2762fc-4c3e-42fe-8b90-33347f6bfe1e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0f2762fc-4c3e-42fe-8b90-33347f6bfe1e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(test_data[:6])\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 769,\n        \"max\": 888,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          888,\n          769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FalseSent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"he did hear music in his cooling glass\",\n          \"Computers is an ingredient used in preparing food\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reason\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Computers are not used for food and they are not edible\",\n          \"Computer is not something that can be used in preparing food.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test DataFrame:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       id                                       FalseSent  \\\n",
              "76   1280           Beer that is drunk by humans is white   \n",
              "101   860  eating trash food every day makes you stronger   \n",
              "136   777             he put some cooking oil in his wine   \n",
              "174   570                  Lobsters live in the mountains   \n",
              "210  1929                         the clock shows animals   \n",
              "235  1619              she put the giraffe in the freezer   \n",
              "\n",
              "                                                      reason1  \\\n",
              "76            Beer is made of barley and it is a yellow drink   \n",
              "101  eating trash food every day makes your body fat and weak   \n",
              "136            cooking oil will destroy the taste of the wine   \n",
              "174                              Lobsters needs water to live   \n",
              "210              the clock is used to show the time to people   \n",
              "235                 A giraffe is much bigger than the freezer   \n",
              "\n",
              "                                                    reason2  \\\n",
              "76             A beer that is drunk by humans is not white.   \n",
              "101      eating trash food every day is bad for your health   \n",
              "136                         Cooking oil does not go in wine   \n",
              "174                               Lobsters live in the sea.   \n",
              "210  Clocks are required to tell the time, not show animals   \n",
              "235    There is no way a giraffe is fitting in the freezer.   \n",
              "\n",
              "                                                                reason3  \n",
              "76                                                        Beer is brown  \n",
              "101                                    Trash food could be contaminated  \n",
              "136  Cooking oil does not taste nice and therefore would ruin the wine.  \n",
              "174                         Lobsters live in the sea, not the mountains  \n",
              "210                                  a clock shows the time not animals  \n",
              "235                        A giraffe is too big to be put in a freezer.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05c1f41a-1755-4279-adf5-f7d01ea26694\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>FalseSent</th>\n",
              "      <th>reason1</th>\n",
              "      <th>reason2</th>\n",
              "      <th>reason3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>1280</td>\n",
              "      <td>Beer that is drunk by humans is white</td>\n",
              "      <td>Beer is made of barley and it is a yellow drink</td>\n",
              "      <td>A beer that is drunk by humans is not white.</td>\n",
              "      <td>Beer is brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>860</td>\n",
              "      <td>eating trash food every day makes you stronger</td>\n",
              "      <td>eating trash food every day makes your body fat and weak</td>\n",
              "      <td>eating trash food every day is bad for your health</td>\n",
              "      <td>Trash food could be contaminated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>777</td>\n",
              "      <td>he put some cooking oil in his wine</td>\n",
              "      <td>cooking oil will destroy the taste of the wine</td>\n",
              "      <td>Cooking oil does not go in wine</td>\n",
              "      <td>Cooking oil does not taste nice and therefore would ruin the wine.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>570</td>\n",
              "      <td>Lobsters live in the mountains</td>\n",
              "      <td>Lobsters needs water to live</td>\n",
              "      <td>Lobsters live in the sea.</td>\n",
              "      <td>Lobsters live in the sea, not the mountains</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>1929</td>\n",
              "      <td>the clock shows animals</td>\n",
              "      <td>the clock is used to show the time to people</td>\n",
              "      <td>Clocks are required to tell the time, not show animals</td>\n",
              "      <td>a clock shows the time not animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>1619</td>\n",
              "      <td>she put the giraffe in the freezer</td>\n",
              "      <td>A giraffe is much bigger than the freezer</td>\n",
              "      <td>There is no way a giraffe is fitting in the freezer.</td>\n",
              "      <td>A giraffe is too big to be put in a freezer.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05c1f41a-1755-4279-adf5-f7d01ea26694')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05c1f41a-1755-4279-adf5-f7d01ea26694 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05c1f41a-1755-4279-adf5-f7d01ea26694');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb38fcf7-1cbf-40a0-88dd-b656953c44aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb38fcf7-1cbf-40a0-88dd-b656953c44aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb38fcf7-1cbf-40a0-88dd-b656953c44aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(test_data[:6])\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 529,\n        \"min\": 570,\n        \"max\": 1929,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1280,\n          860,\n          1619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FalseSent\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Beer that is drunk by humans is white\",\n          \"eating trash food every day makes you stronger\",\n          \"she put the giraffe in the freezer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reason1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Beer is made of barley and it is a yellow drink\",\n          \"eating trash food every day makes your body fat and weak\",\n          \"A giraffe is much bigger than the freezer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reason2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"A beer that is drunk by humans is not white.\",\n          \"eating trash food every day is bad for your health\",\n          \"There is no way a giraffe is fitting in the freezer.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reason3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Beer is brown\",\n          \"Trash food could be contaminated\",\n          \"A giraffe is too big to be put in a freezer.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data_csv = \"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_data_all.csv\"\n",
        "train_answers_csv = \"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_answers_all.csv\"\n",
        "train_data = load_data(train_data_csv, train_answers_csv)\n",
        "dev_data_csv = \"SemEval2020-Task4-Data/ALL data/Dev Data/subtaskC_dev_data.csv\"\n",
        "dev_answers_csv = \"SemEval2020-Task4-Data/ALL data/Dev Data/subtaskC_gold_answers.csv\"\n",
        "dev_data = load_data(dev_data_csv, dev_answers_csv)\n",
        "test_data_csv = \"SemEval2020-Task4-Data/ALL data/Test Data/subtaskC_test_data.csv\"\n",
        "test_answers_csv = \"SemEval2020-Task4-Data/ALL data/Test Data/subtaskC_gold_answers.csv\"\n",
        "test_data = load_data(test_data_csv, test_answers_csv, True)\n",
        "if shrink_dataset:\n",
        "    idxs = train_data[\"id\"].sample(frac=1, random_state=42).unique()[:30]\n",
        "    train_data = train_data[train_data.id.isin(idxs)]\n",
        "    idxs = dev_data[\"id\"].sample(frac=1, random_state=42).unique()[:30]\n",
        "    dev_data = dev_data[dev_data.id.isin(idxs)]\n",
        "    idxs = test_data[\"id\"].sample(frac=1, random_state=42).unique()[:30]\n",
        "    test_data = test_data[test_data.id.isin(idxs)]\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "print(\"Train DataFrame:\")\n",
        "display(train_data[:6])\n",
        "print(\"Test DataFrame:\")\n",
        "display(test_data[:6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DJU-01EtDfh1",
        "outputId": "ed4a469a-d176-4371-f6ba-c2c52e0bd594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset example:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 769,\n",
              " 'FalseSent': 'Computers is an ingredient used in preparing food',\n",
              " 'reason': 'Computers are not used for food and they are not edible',\n",
              " '__index_level_0__': 769}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Dataset example:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 1280,\n",
              " 'FalseSent': 'Beer that is drunk by humans is white',\n",
              " 'reason1': 'Beer is made of barley and it is a yellow drink',\n",
              " 'reason2': 'A beer that is drunk by humans is not white.',\n",
              " 'reason3': 'Beer is brown',\n",
              " '__index_level_0__': 76}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "dev_dataset = Dataset.from_pandas(dev_data)\n",
        "test_dataset = Dataset.from_pandas(test_data)\n",
        "print(\"Train Dataset example:\")\n",
        "display(train_dataset[0])\n",
        "print(\"Test Dataset example:\")\n",
        "display(test_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HsEcHmGiDfh1"
      },
      "source": [
        "The `Datasets` should be pre-processed following two different approaches. For the test `Dataset`, you must run the tokenizer on the `FalseSent` column and store the result in the `input_ids` and `attention_mask` fields. For the train and development `Datasets` you must also run the tokenizer on the `reason` column and store the resulting `input_ids` in the `labels` field. In all cases, the tokenizer must pad and truncate the sequences to the `max_length` value.\n",
        "\n",
        "><pre>\n",
        ">Train formated Dataset example:\n",
        ">\n",
        ">{'id': 769, 'FalseSent': 'Computers is an ingredient used in preparing food', 'reason': 'Computers are not used for food and they are not edible', '__index_level_0__': 769, 'input_ids': [0, 14721, 43990, 16, 41, 16181, 341, 11, 4568, 689, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0, 14721, 43990, 32, 45, 341, 13, 689, 8, 51, 32, 45, 27532, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
        ">\n",
        ">Test formated Dataset example:\n",
        ">\n",
        ">{'id': 1280, 'FalseSent': 'Beer that is drunk by humans is white', 'reason1': 'Beer is made of barley and it is a yellow drink', 'reason2': 'A beer that is drunk by humans is not white.', 'reason3': 'Beer is brown', '__index_level_0__': 76, 'input_ids': [0, 45562, 14, 16, 10789, 30, 5868, 16, 1104, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
        "></pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y17HBOk0Dfh1"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(examples, tokenizer, max_length, is_test=False):   # [1 Mark]\n",
        "    #\n",
        "    input_ids= []\n",
        "    attention_mask = []\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    if is_test:\n",
        "      for i, data in enumerate(examples[\"FalseSent\"]):\n",
        "        result = tokenizer(data, padding = 'max_length', max_length = max_length, truncation=True)\n",
        "        input_ids.append(result[\"input_ids\"])\n",
        "        attention_mask.append(result[\"attention_mask\"])\n",
        "      return {\n",
        "          \"input_ids\" : input_ids,\n",
        "          \"attention_mask\" : attention_mask\n",
        "      }\n",
        "\n",
        "    else:\n",
        "      for i, data in enumerate(examples[\"reason\"]):\n",
        "        result = tokenizer(data, padding= 'max_length', max_length = max_length, truncation=True)\n",
        "        input_ids.append(result[\"input_ids\"])\n",
        "        attention_mask.append(result[\"attention_mask\"])\n",
        "      return {\n",
        "         \"input_ids\" : input_ids,\n",
        "          \"attention_mask\" : attention_mask,\n",
        "         \"labels\" : input_ids\n",
        "    }\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(examples, tokenizer, max_length, is_test=False):\n",
        "    # Tokenizing the FalseSent column for both train and test sets\n",
        "    inputs = tokenizer(\n",
        "        examples['FalseSent'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Initialize the output dictionary\n",
        "    result = {\n",
        "        'id': examples['id'],  # Keep the id from the original data\n",
        "        'FalseSent': examples['FalseSent'],  # Keep the FalseSent statement\n",
        "        '__index_level_0__': examples['id'],  # To preserve index\n",
        "        'input_ids': inputs['input_ids'],  # Tokenized FalseSent\n",
        "        'attention_mask': inputs['attention_mask'],  # Attention mask for FalseSent\n",
        "    }\n",
        "\n",
        "    if not is_test:\n",
        "        # For train and development data, also tokenize the reason column and store it in the labels field\n",
        "        # Tokenizing the reason column\n",
        "        labels = tokenizer(\n",
        "            examples['reason'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Adding the labels (reason) to the result dictionary\n",
        "        result['labels'] = labels['input_ids']\n",
        "\n",
        "    else:\n",
        "        # For test set, store reasons as reason1, reason2, reason3\n",
        "        reasons = ['reason1', 'reason2', 'reason3']\n",
        "        for idx, reason in enumerate(reasons):\n",
        "            reason_tokenized = tokenizer(\n",
        "                examples[reason],\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            result[f'input_ids_{idx+1}'] = reason_tokenized['input_ids']\n",
        "            result[f'attention_mask_{idx+1}'] = reason_tokenized['attention_mask']\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "D_PYFVikY11D"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TYDVjG1SDfh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259,
          "referenced_widgets": [
            "7468e236423540f0828a78d8f12cb76a",
            "286e8ee21bb84dc8b0b982721f17e3f9",
            "53ddbd6a139444ea97f06c9351a0c197",
            "51c57f9621db4301aae68f4c621e6cdf",
            "407a264855d2460097ea51525c2aa317",
            "7d316c27fac0430b93dc0ac6b92a71cb",
            "05738711b01d450b9fd109c25009beda",
            "a5ccedd671e348d18603768f989dadce",
            "0785b2d8e96f4658986d068f48f1d9c3",
            "f11423df5b674585a04dbff5e1b1721e",
            "6a76ab419df24e689a22bf0945d58bf4",
            "c93f1fb9d545462ba9126fdf58a07082",
            "574291f6366249f186dddd6f597fa907",
            "23a0a773a6544a4d91089e2b616d854b",
            "28af9b63f1a14f0cac11487207095b23",
            "4912bbe115cc433ebd4e18eb318ade46",
            "41807243a2c64d3ca385716497d5a119",
            "8bd3899f0e534aaaab93b393296f853a",
            "99a472c601ee40b7a015ba9aba3486d4",
            "ea033a548919407a9bdfa059015e0e5d",
            "fc883f337d874013b8cd9a3048347094",
            "cf911140d6834244aaaf20ae69c5730e",
            "7252f3c442874a7c900b11fb73a2d111",
            "b7e21b79e08b491e9abaa835dfaca538",
            "427c921a463b42db8082994ac6d52400",
            "58904854fc9649a19d9b96203abd8f89",
            "76cedc55f5d84fc3bb29b5a6edfc1693",
            "6f399a4c4a5a46f3bc2ec6d6c4d53f4e",
            "e7b00460bbef4acdaf8894de19f323c4",
            "ffcf785beb7045b49bc12231005c3257",
            "ff76c88d91ee463bac8651a283355e1d",
            "351262e5e9e844bfbf0dcd6ac71e9c7c",
            "f967856be33444ee9036913ae5c9e513"
          ]
        },
        "outputId": "9680f5a8-ed30-4984-9c64-e2b4728e3f32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7468e236423540f0828a78d8f12cb76a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c93f1fb9d545462ba9126fdf58a07082"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7252f3c442874a7c900b11fb73a2d111"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train formated Dataset example:\n",
            "\n",
            "{'id': 769, 'FalseSent': 'Computers is an ingredient used in preparing food', 'reason': 'Computers are not used for food and they are not edible', '__index_level_0__': 769, 'input_ids': [0, 14721, 43990, 32, 45, 341, 13, 689, 8, 51, 32, 45, 27532, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0, 14721, 43990, 32, 45, 341, 13, 689, 8, 51, 32, 45, 27532, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "Test formated Dataset example:\n",
            "\n",
            "{'id': 1280, 'FalseSent': 'Beer that is drunk by humans is white', 'reason1': 'Beer is made of barley and it is a yellow drink', 'reason2': 'A beer that is drunk by humans is not white.', 'reason3': 'Beer is brown', '__index_level_0__': 76, 'input_ids': [0, 45562, 14, 16, 10789, 30, 5868, 16, 1104, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "train_dataset = train_dataset.map(lambda x: preprocess_data(x, tokenizer, max_length), batched=True)\n",
        "dev_dataset = dev_dataset.map(lambda x: preprocess_data(x, tokenizer, max_length), batched=True)\n",
        "test_dataset = test_dataset.map(lambda x: preprocess_data(x, tokenizer, max_length, True), batched=True)\n",
        "print(\"Train formated Dataset example:\\n\")\n",
        "print(train_dataset[0])\n",
        "print(\"\\nTest formated Dataset example:\\n\")\n",
        "print(test_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SE65PJbXDfh2"
      },
      "source": [
        "## Fine-tuning - [5 Marks]\n",
        "\n",
        "In general, when using a `Trainer` to make predictions, it returns the logits for each class in the task. However, the `Seq2SeqTrainingArguments` class provides an option that allows the `Trainer` to generate sequences of tokens in the prediction. The `create_training_arguments` function must create the `Seq2SeqTrainingArguments` with that option and the hyperparamters passed as arguments. During the training, the model must be evaluated on the development set after every epoch. `TrainingArguments` should include this strategy.\n",
        "\n",
        "> **Important!** By default, `Trainer` saves a checkpoint of the model every 500 training steps. For this assignment, avoid this behavior by setting `save_strategy=\"no\"` when creating the `TrainingArguments`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NYcGf9LtDfh2"
      },
      "outputs": [],
      "source": [
        "def create_training_arguments(epochs, train_batch_size, learning_rate, output_dir):   # [1 Mark]\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir= output_dir,\n",
        "        learning_rate= learning_rate,\n",
        "        per_device_train_batch_size= train_batch_size,\n",
        "        per_device_eval_batch_size= train_batch_size,\n",
        "        num_train_epochs= epochs,\n",
        "        save_strategy= \"no\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        predict_with_generate=True\n",
        "        #logging_steps=500,\n",
        "        #prediction_loss_only=False\n",
        "    )\n",
        "    return training_args\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_training_arguments(epochs, train_batch_size, learning_rate, output_dir):\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=output_dir,  # Directory to save the model and checkpoints\n",
        "        evaluation_strategy=\"epoch\",  # Evaluate the model at the end of every epoch\n",
        "        save_strategy=\"no\",  # Prevent saving checkpoints every 500 steps\n",
        "        num_train_epochs=epochs,  # Number of training epochs\n",
        "        per_device_train_batch_size=train_batch_size,  # Batch size for training\n",
        "        per_device_eval_batch_size=train_batch_size,  # Batch size for evaluation (same as training for consistency)\n",
        "        learning_rate=learning_rate,  # Learning rate for the optimizer\n",
        "        logging_dir=\"./logs\",  # Directory to store logs (optional)\n",
        "        logging_steps=50,  # Log every 50 steps (you can adjust this as needed)\n",
        "        predict_with_generate=True,  # Enable sequence generation during predictions\n",
        "        #load_best_model_at_end=True,  # Load the best model based on evaluation metric\n",
        "        metric_for_best_model=\"loss\",  # Use loss as the metric for selecting the best model\n",
        "        greater_is_better=False,  # Lower loss is better\n",
        "        warmup_steps=500,  # Number of warmup steps for the learning rate scheduler (optional)\n",
        "        weight_decay=0.01,  # Weight decay to avoid overfitting (optional)\n",
        "        logging_first_step=True,  # Log the first step as well\n",
        "    )\n",
        "\n",
        "    return training_args\n"
      ],
      "metadata": {
        "id": "gB9-DT5GZn-M"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "OMIWd-JsDfh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59222ff6-1435-4c0f-eef6-2bc3b871777a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_args = create_training_arguments(epochs, train_batch_size, learning_rate, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LlaJ4yJxDfh2"
      },
      "source": [
        "Next, you can create a `Trainer` object initializing the appropriate data collator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b3Zqw2vpDfh2"
      },
      "outputs": [],
      "source": [
        "def create_trainer(model, train_args, train_dataset, dev_dataset, tokenizer):   # [1 Mark]\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    data_collator= DataCollatorForSeq2Seq(tokenizer=tokenizer, model = model)\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model = model,\n",
        "        args = train_args,\n",
        "        train_dataset = train_dataset,\n",
        "        eval_dataset = dev_dataset,\n",
        "        tokenizer = tokenizer,\n",
        "        data_collator= data_collator\n",
        "    )\n",
        "    return trainer\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trainer(model, training_args, train_dataset, eval_dataset, tokenizer):\n",
        "    # Load pre-trained model and tokenizer\n",
        "\n",
        "    # Initialize the DataCollatorForSeq2Seq, which will pad the sequences dynamically during training\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "    # Initialize the Trainer\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,  # The model to train\n",
        "        args=training_args,  # Training arguments created earlier\n",
        "        train_dataset=train_dataset,  # The training dataset\n",
        "        eval_dataset=eval_dataset,  # The evaluation (development) dataset\n",
        "        tokenizer=tokenizer,  # The tokenizer to process data\n",
        "        data_collator=data_collator,  # The data collator to handle padding\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "z4imFIIKaVt0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3E2txek_Dfh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce05129d-4d74-4971-8876-98c84fb311fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3cf9657cb6f9>:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "trainer = create_trainer(model, train_args, train_dataset, dev_dataset, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wtQpnSvdDfh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "63e3761d-69b7-4ae5-888c-822ca9a56db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxuan-nguyen-intel\u001b[0m (\u001b[33mxuan-nguyen-intel-intel\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250222_072131-1aaqcjfx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/xuan-nguyen-intel-intel/huggingface/runs/1aaqcjfx' target=\"_blank\">modelC</a></strong> to <a href='https://wandb.ai/xuan-nguyen-intel-intel/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/xuan-nguyen-intel-intel/huggingface' target=\"_blank\">https://wandb.ai/xuan-nguyen-intel-intel/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/xuan-nguyen-intel-intel/huggingface/runs/1aaqcjfx' target=\"_blank\">https://wandb.ai/xuan-nguyen-intel-intel/huggingface/runs/1aaqcjfx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36/36 03:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.020969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.532254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.361630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=36, training_loss=6.958015441894531, metrics={'train_runtime': 215.1862, 'train_samples_per_second': 1.255, 'train_steps_per_second': 0.167, 'total_flos': 4019258880000.0, 'train_loss': 6.958015441894531, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e7Dq4Z3QDfh2"
      },
      "source": [
        "If you have set the `Seq2SeqTrainingArguments` properly, you could now use the `Trainer` to predict sequences of tokens. Take into account that `Trainer` will return the indexes of the tokens, so the sequence must be decoded to obtain the text strings. The `tokenizer` provides functionality to do this. The result of this process can be stored in the `prediction` column of the test `DataFrame`:\n",
        "\n",
        "|     |   id | FalseSent                                      | reason1                                                  | reason2                                                | reason3                                                            | prediction                                     |\n",
        "|----:|-----:|:-----------------------------------------------|:---------------------------------------------------------|:-------------------------------------------------------|:-------------------------------------------------------------------|:-----------------------------------------------|\n",
        "|  76 | 1280 | Beer that is drunk by humans is white          | Beer is made of barley and it is a yellow drink          | A beer that is drunk by humans is not white.           | Beer is brown                                                      | Beer that is drunk by humans is white                             |\n",
        "| 101 |  860 | eating trash food every day makes you stronger | eating trash food every day makes your body fat and weak | eating trash food every day is bad for your health     | Trash food could be contaminated                                   | eating trash food every day makes you stronger |\n",
        "| 136 |  777 | he put some cooking oil in his wine            | cooking oil will destroy the taste of the wine           | Cooking oil does not go in wine                        | Cooking oil does not taste nice and therefore would ruin the wine. | he put some cooking oil in his wine            |\n",
        "| 174 |  570 | Lobsters live in the mountains                 | Lobsters needs water to live                             | Lobsters live in the sea.                              | Lobsters live in the sea, not the mountains                        | Lobsters live in mountains                 |\n",
        "| 210 | 1929 | the clock shows animals                        | the clock is used to show the time to people             | Clocks are required to tell the time, not show animals | a clock shows the time not animals                                 | the clock shows animals                        |\n",
        "| 235 | 1619 | she put the giraffe in the freezer             | A giraffe is much bigger than the freezer                | There is no way a giraffe is fitting in the freezer.   | A giraffe is too big to be put in a freezer.                       | she put the giraffe in the freezer             |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8igEq42FDfh2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_predictions(trainer, test_dataset, tokenizer):   # [1 Mark]\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    logits = predictions.predictions[0].argmax(axis= -1)  # This is a 3D array: (batch_size, sequence_length, vocab_size)\n",
        "\n",
        "    predictions_de = tokenizer.batch_decode(logits, skip_special_tokens=True)\n",
        "    #print(predictions_de\n",
        "    ##print( predictions_de)\n",
        "    return predictions_de\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(trainer, test_dataset, tokenizer):\n",
        "    # Get predictions from the trainer\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "\n",
        "    # `predictions.predictions` is a tuple, where the first item is the logits\n",
        "    logits = predictions.predictions # The logits output from the model\n",
        "\n",
        "    # Get the token IDs with the highest probability for each position in the sequence\n",
        "    predicted_ids = logits.argmax(axis=-1)  # Find the argmax across the vocabulary dimension\n",
        "\n",
        "    # Decode the predicted token IDs into strings\n",
        "    decoded_predictions = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Return the decoded predictions\n",
        "    return decoded_predictions\n"
      ],
      "metadata": {
        "id": "jd0ygfJydbaA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zaptZPfJDfh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "665dddf2-8b42-4655-adc1-11fc9e6e53dd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'loss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2b5da2632c51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-7eb46d66b1e7>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(trainer, test_dataset, tokenizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#  REPLACE THE pass STATEMENT WITH YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This is a 3D array: (batch_size, sequence_length, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     def prediction_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4150\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4151\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4152\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4153\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4267\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4268\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m             inputs_decode = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'loss'"
          ]
        }
      ],
      "source": [
        "predictions = make_predictions(trainer, test_dataset, tokenizer)\n",
        "test_data[\"prediction\"] = predictions\n",
        "test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2gAv_hl0Dfh3"
      },
      "source": [
        "The **Subtasks B** of **ComVE** is evaluated using the *bleu* metric. In this assignment, you will also evaluate using *rouge*. With `shrink_dataset` and `base_model` set to `True`, the expected scores are *0.216* and *0.446* for *bleu* and *rouge* respectively. With a full training run, i.e. with `shrink_dataset` and `base_model` set to `False`, the scores should be around *0.228* and *0.461*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yDJ79cPoDfh3"
      },
      "outputs": [],
      "source": [
        "def evaluate_prediction(test_data, metric):   # [2 Marks]\n",
        "    #\n",
        "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
        "    #\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MztCvvWyDfh3"
      },
      "outputs": [],
      "source": [
        " evaluate_prediction(test_data, \"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7aIBv1uODfh3"
      },
      "outputs": [],
      "source": [
        "evaluate_prediction(test_data, \"rouge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "s0D-JhuDDfh3"
      },
      "source": [
        "The scores for the partial training and the full training are so similar that it would appear that the full training does not provide any benefit in this task. However, it should be noted that the test sets in the two cases are different. More importantly, these results are indicative of the limitations of metrics such as *bleu* and *rouge* for evaluating text generation. Take, for example, the following case from the test set:\n",
        "\n",
        "\n",
        "| FalseSent                 | reason1                                        | reason2                          | reason3                         |\n",
        "|:--------------------------|:-----------------------------------------------|:---------------------------------|:--------------------------------|\n",
        "| Beer that is drunk by humans is white | Beer is made of barley and it is a yellow drink | A beer that is drunk by humans is not white. | Beer is brown |\n",
        "\n",
        "The predictions obtained by the partial and full trainings and their corresponding scores are the following:\n",
        "\n",
        "| full training    | prediction                 | bleu     | rouge    |\n",
        "|:-----------------|:---------------------------|---------:|---------:|\n",
        "| no               | Beer that is drunk by humans is white  | 0.731    | 0.889    |\n",
        "| yes              | White beer is not suitable for human consumption. | 0.000    | 0.364    |\n",
        "\n",
        "The text generated by the full training is a better explanation than the reason generated by the partial training, which is a mere repetition of the nonsensical statement. However, the latter obtains much better scores than the former. Metrics such as *bleu* and *rouge* do not always replace accurately the human judgement."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7468e236423540f0828a78d8f12cb76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_286e8ee21bb84dc8b0b982721f17e3f9",
              "IPY_MODEL_53ddbd6a139444ea97f06c9351a0c197",
              "IPY_MODEL_51c57f9621db4301aae68f4c621e6cdf"
            ],
            "layout": "IPY_MODEL_407a264855d2460097ea51525c2aa317"
          }
        },
        "286e8ee21bb84dc8b0b982721f17e3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d316c27fac0430b93dc0ac6b92a71cb",
            "placeholder": "​",
            "style": "IPY_MODEL_05738711b01d450b9fd109c25009beda",
            "value": "Map: 100%"
          }
        },
        "53ddbd6a139444ea97f06c9351a0c197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ccedd671e348d18603768f989dadce",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0785b2d8e96f4658986d068f48f1d9c3",
            "value": 90
          }
        },
        "51c57f9621db4301aae68f4c621e6cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f11423df5b674585a04dbff5e1b1721e",
            "placeholder": "​",
            "style": "IPY_MODEL_6a76ab419df24e689a22bf0945d58bf4",
            "value": " 90/90 [00:00&lt;00:00, 1634.82 examples/s]"
          }
        },
        "407a264855d2460097ea51525c2aa317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d316c27fac0430b93dc0ac6b92a71cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05738711b01d450b9fd109c25009beda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ccedd671e348d18603768f989dadce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0785b2d8e96f4658986d068f48f1d9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f11423df5b674585a04dbff5e1b1721e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a76ab419df24e689a22bf0945d58bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c93f1fb9d545462ba9126fdf58a07082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_574291f6366249f186dddd6f597fa907",
              "IPY_MODEL_23a0a773a6544a4d91089e2b616d854b",
              "IPY_MODEL_28af9b63f1a14f0cac11487207095b23"
            ],
            "layout": "IPY_MODEL_4912bbe115cc433ebd4e18eb318ade46"
          }
        },
        "574291f6366249f186dddd6f597fa907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41807243a2c64d3ca385716497d5a119",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd3899f0e534aaaab93b393296f853a",
            "value": "Map: 100%"
          }
        },
        "23a0a773a6544a4d91089e2b616d854b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99a472c601ee40b7a015ba9aba3486d4",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea033a548919407a9bdfa059015e0e5d",
            "value": 90
          }
        },
        "28af9b63f1a14f0cac11487207095b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc883f337d874013b8cd9a3048347094",
            "placeholder": "​",
            "style": "IPY_MODEL_cf911140d6834244aaaf20ae69c5730e",
            "value": " 90/90 [00:00&lt;00:00, 1749.94 examples/s]"
          }
        },
        "4912bbe115cc433ebd4e18eb318ade46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41807243a2c64d3ca385716497d5a119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd3899f0e534aaaab93b393296f853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99a472c601ee40b7a015ba9aba3486d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea033a548919407a9bdfa059015e0e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc883f337d874013b8cd9a3048347094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf911140d6834244aaaf20ae69c5730e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7252f3c442874a7c900b11fb73a2d111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7e21b79e08b491e9abaa835dfaca538",
              "IPY_MODEL_427c921a463b42db8082994ac6d52400",
              "IPY_MODEL_58904854fc9649a19d9b96203abd8f89"
            ],
            "layout": "IPY_MODEL_76cedc55f5d84fc3bb29b5a6edfc1693"
          }
        },
        "b7e21b79e08b491e9abaa835dfaca538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f399a4c4a5a46f3bc2ec6d6c4d53f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_e7b00460bbef4acdaf8894de19f323c4",
            "value": "Map: 100%"
          }
        },
        "427c921a463b42db8082994ac6d52400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffcf785beb7045b49bc12231005c3257",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff76c88d91ee463bac8651a283355e1d",
            "value": 30
          }
        },
        "58904854fc9649a19d9b96203abd8f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351262e5e9e844bfbf0dcd6ac71e9c7c",
            "placeholder": "​",
            "style": "IPY_MODEL_f967856be33444ee9036913ae5c9e513",
            "value": " 30/30 [00:00&lt;00:00, 931.49 examples/s]"
          }
        },
        "76cedc55f5d84fc3bb29b5a6edfc1693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f399a4c4a5a46f3bc2ec6d6c4d53f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b00460bbef4acdaf8894de19f323c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffcf785beb7045b49bc12231005c3257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff76c88d91ee463bac8651a283355e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "351262e5e9e844bfbf0dcd6ac71e9c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f967856be33444ee9036913ae5c9e513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}